{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to reframe the vectors to prepare for a multivariate supervised training of time series\n",
    "\n",
    "source: https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>amount_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1498050000</td>\n",
       "      <td>26805</td>\n",
       "      <td>45733.59</td>\n",
       "      <td>285315.95</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>295.37</td>\n",
       "      <td>25</td>\n",
       "      <td>290.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>2017-06-21 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1486310400</td>\n",
       "      <td>27487</td>\n",
       "      <td>50781.62</td>\n",
       "      <td>262346.81</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>273.91</td>\n",
       "      <td>17</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>2017-02-05 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1464897600</td>\n",
       "      <td>41686</td>\n",
       "      <td>71816.81</td>\n",
       "      <td>400042.82</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>296.72</td>\n",
       "      <td>6</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>2016-06-02 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1456308000</td>\n",
       "      <td>31526</td>\n",
       "      <td>44498.25</td>\n",
       "      <td>291332.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>275.77</td>\n",
       "      <td>15</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>2016-02-24 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1458097200</td>\n",
       "      <td>4138</td>\n",
       "      <td>9353.05</td>\n",
       "      <td>42545.26</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>282.52</td>\n",
       "      <td>17</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>2016-03-16 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  passenger_count  trip_distance  total_amount  humidity  \\\n",
       "0  1498050000            26805       45733.59     285315.95      57.0   \n",
       "1  1486310400            27487       50781.62     262346.81      51.0   \n",
       "2  1464897600            41686       71816.81     400042.82      82.0   \n",
       "3  1456308000            31526       44498.25     291332.16      86.0   \n",
       "4  1458097200             4138        9353.05      42545.26      81.0   \n",
       "\n",
       "   pressure  temperature  weather_description  wind_direction  wind_speed  \\\n",
       "0    1014.0       295.37                   25           290.0         3.0   \n",
       "1    1016.0       273.91                   17           250.0         5.0   \n",
       "2    1020.0       296.72                    6            90.0         5.0   \n",
       "3    1019.0       275.77                   15            70.0         6.0   \n",
       "4    1010.0       282.52                   17            15.0         1.0   \n",
       "\n",
       "   amount_rate                 time  \n",
       "0     0.000233  2017-06-21 15:00:00  \n",
       "1     0.000188  2017-02-05 17:00:00  \n",
       "2     0.000134  2016-06-02 22:00:00  \n",
       "3     0.000208  2016-02-24 11:00:00  \n",
       "4     0.001099  2016-03-16 04:00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the cleaned dataframe by the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sort_values('time', ascending=True, inplace = True)\n",
    "train_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timearr = train_df.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['timestamp', 'time'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the values from the dataframe to a two dimension vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = train_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the X and y values with a MinMaxScaler to optimize the loss functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = vals[:,1:]\n",
    "y_vals = vals[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals_scaled = X_scaler.fit_transform(x_vals)\n",
    "y_vals_scaled = y_scaler.fit_transform(y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_scaled = np.concatenate((y_vals_scaled, x_vals_scaled), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reframing the dataframe for multivariate supervised timeseries modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_scaled_reframed = series_to_supervised(vals_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_scaled_reframed.drop(['var1(t)','var2(t)','var3(t)','var4(t)','var5(t)','var6(t)','var7(t)','var8(t)','var9(t)','var10(t)'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_final = vals_scaled_reframed.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac = 0.20\n",
    "train_size = int(round(vals_final.shape[0]*(1-test_frac)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = vals_final[:train_size, :]\n",
    "test_set = vals_final[train_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_set[:,1:], train_set[:,:1] \n",
    "X_test, y_test = test_set[:,1:], test_set[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple LSTM model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                19456     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 19,521\n",
      "Trainable params: 19,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the next cell if you experience OS errors on mac if in case the keras model training doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the keras model for 50 epochs \n",
    "(asymptote on the loss reaches around 30 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12798 samples, validate on 3199 samples\n",
      "Epoch 1/50\n",
      " - 11s - loss: 0.0967 - val_loss: 0.0846\n",
      "Epoch 2/50\n",
      " - 4s - loss: 0.0846 - val_loss: 0.0842\n",
      "Epoch 3/50\n",
      " - 5s - loss: 0.0843 - val_loss: 0.0841\n",
      "Epoch 4/50\n",
      " - 5s - loss: 0.0841 - val_loss: 0.0840\n",
      "Epoch 5/50\n",
      " - 4s - loss: 0.0839 - val_loss: 0.0839\n",
      "Epoch 6/50\n",
      " - 4s - loss: 0.0838 - val_loss: 0.0838\n",
      "Epoch 7/50\n",
      " - 4s - loss: 0.0837 - val_loss: 0.0838\n",
      "Epoch 8/50\n",
      " - 5s - loss: 0.0837 - val_loss: 0.0838\n",
      "Epoch 9/50\n",
      " - 4s - loss: 0.0836 - val_loss: 0.0837\n",
      "Epoch 10/50\n",
      " - 5s - loss: 0.0836 - val_loss: 0.0837\n",
      "Epoch 11/50\n",
      " - 4s - loss: 0.0836 - val_loss: 0.0837\n",
      "Epoch 12/50\n",
      " - 5s - loss: 0.0836 - val_loss: 0.0837\n",
      "Epoch 13/50\n",
      " - 4s - loss: 0.0836 - val_loss: 0.0837\n",
      "Epoch 14/50\n",
      " - 5s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 15/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 16/50\n",
      " - 5s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 17/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 18/50\n",
      " - 5s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 19/50\n",
      " - 5s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 20/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 21/50\n",
      " - 5s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 22/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 23/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 24/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 25/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 26/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 27/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 28/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 29/50\n",
      " - 4s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 30/50\n",
      " - 6s - loss: 0.0835 - val_loss: 0.0837\n",
      "Epoch 31/50\n",
      " - 6s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 32/50\n",
      " - 5s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 33/50\n",
      " - 4s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 34/50\n",
      " - 6s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 35/50\n",
      " - 5s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 36/50\n",
      " - 5s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 37/50\n",
      " - 5s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 38/50\n",
      " - 5s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 39/50\n",
      " - 5s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 40/50\n",
      " - 4s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 41/50\n",
      " - 4s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 42/50\n",
      " - 4s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 43/50\n",
      " - 4s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 44/50\n",
      " - 4s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 45/50\n",
      " - 4s - loss: 0.0834 - val_loss: 0.0837\n",
      "Epoch 46/50\n",
      " - 4s - loss: 0.0834 - val_loss: 0.0838\n",
      "Epoch 47/50\n",
      " - 4s - loss: 0.0834 - val_loss: 0.0838\n",
      "Epoch 48/50\n",
      " - 5s - loss: 0.0834 - val_loss: 0.0838\n",
      "Epoch 49/50\n",
      " - 5s - loss: 0.0834 - val_loss: 0.0838\n",
      "Epoch 50/50\n",
      " - 6s - loss: 0.0834 - val_loss: 0.0838\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,  epochs=50, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss over training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a4cf20fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], label='train')\n",
    "plt.plot(hist.history['val_loss'], label='test')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "invert scaling for forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = np.concatenate((yhat, X_test[:, 1:]), axis=1)\n",
    "inv_yhat = y_scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "invert scaling for actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape((len(y_test), 1))\n",
    "inv_y = np.concatenate((y_test, X_test[:, 1:]), axis=1)\n",
    "inv_y = y_scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 4629.946\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
